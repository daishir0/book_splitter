#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›¸ç±æ§‹é€ åŒ–åˆ†å‰²ãƒ„ãƒ¼ãƒ«ï¼ˆTextBookStructurerï¼‰
==================================================

ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®æ›¸ç±ã‚’è§£æã—ã€ç« ãƒ»ç¯€ã«åˆ†å‰²ã—ã¦æ§‹é€ åŒ–ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
AIã‚’æ´»ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³ã‚’ç†è§£ã—ãªãŒã‚‰é©åˆ‡ãªåˆ†å‰²ã‚’è¡Œã„ã€YAMLå½¢å¼ã§å‡ºåŠ›ã—ã¾ã™ã€‚

ä¸»ãªæ©Ÿèƒ½:
-------
- AIã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆæ§‹é€ ã®åˆ†æ
- ç« ãƒ»ç¯€ã®è‡ªå‹•æ¤œå‡ºã¨åˆ†å‰²
- ã‚¿ã‚¤ãƒˆãƒ«ãƒ»è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è‡ªå‹•ç”Ÿæˆ
- æ–‡ç« ã®å¢ƒç•Œèª¿æ•´ã«ã‚ˆã‚‹å®Œçµæ€§ã®ç¢ºä¿
- YAMLå½¢å¼ã§ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›

ä½¿ç”¨æ–¹æ³•:
-------
```
python main.py å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
```

ä¾‹:
```
python main.py input.txt output.yaml
```

å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: æ§‹é€ åŒ–ã•ã‚ŒãŸYAMLå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«

å‡ºåŠ›ã•ã‚ŒãŸYAMLãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ã§æ´»ç”¨ã§ãã¾ã™:
- yaml_splitter.py: YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²
- ãã®ä»–ã®YAMLå‡¦ç†ãƒ„ãƒ¼ãƒ«

æ³¨æ„äº‹é …:
-------
- å¤§ããªãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
- OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆconfig.pyã§è¨­å®šï¼‰
"""

import logging
import sys
import argparse
from pathlib import Path
from typing import Dict, Any, List
from dataclasses import dataclass

# LangGraphã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from typing_extensions import Annotated, TypedDict

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import DEBUG
from openai_client import OpenAIClient
from agents.segmenter import SegmenterAgent
from agents.splitter import SplitterAgent
from agents.labeler import LabelerAgent
from agents.yaml_formatter import YAMLFormatterAgent

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ProcessingState(TypedDict):
    """å‡¦ç†çŠ¶æ…‹ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    input_text: str
    book_title: str
    structure_analysis: Dict[str, Any]
    text_chunks: List[Any]
    enriched_chunks: List[Any]
    yaml_data: Dict[str, Any]
    current_step: str
    error_message: str
    processing_complete: bool


class TextBookStructurer:
    """
    æ›¸ç±æ§‹é€ åŒ–åˆ†å‰²ãƒ„ãƒ¼ãƒ«ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    
    LangGraphã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®å”èª¿å‡¦ç†ã‚’ç®¡ç†
    """
    
    def __init__(self, input_file: str, output_file: str):
        """
        åˆæœŸåŒ–
        
        Args:
            input_file: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.input_file = input_file
        self.output_file = output_file
        
        print("ğŸ¤– AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        print("ğŸ“¡ OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–...")
        self.openai_client = OpenAIClient()
        
        print("ğŸ” SegmenterAgentï¼ˆæ§‹é€ æŠ½å‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’åˆæœŸåŒ–...")
        self.segmenter = SegmenterAgent(self.openai_client)
        
        print("âœ‚ï¸  SplitterAgentï¼ˆåˆ†å‰²ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’åˆæœŸåŒ–...")
        self.splitter = SplitterAgent(self.openai_client)
        
        print("ğŸ·ï¸  LabelerAgentï¼ˆãƒ¡ã‚¿ä»˜ä¸ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’åˆæœŸåŒ–...")
        self.labeler = LabelerAgent(self.openai_client)
        
        print("ğŸ“ YAMLFormatterAgentï¼ˆå‡ºåŠ›æ•´å½¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’åˆæœŸåŒ–...")
        self.formatter = YAMLFormatterAgent()
        
        print("ğŸ”— LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ä¸­...")
        # LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰
        self.workflow = self._build_workflow()
        print("âœ… å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print()
        
    def _build_workflow(self) -> StateGraph:
        """
        LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã™ã‚‹
        
        Returns:
            StateGraph: æ§‹ç¯‰ã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
        """
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        workflow = StateGraph(ProcessingState)
        
        # ãƒãƒ¼ãƒ‰ï¼ˆå‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ï¼‰ã‚’è¿½åŠ 
        workflow.add_node("load_input", self._load_input)
        workflow.add_node("analyze_structure", self._analyze_structure)
        workflow.add_node("split_text", self._split_text)
        workflow.add_node("enrich_metadata", self._enrich_metadata)
        workflow.add_node("format_yaml", self._format_yaml)
        workflow.add_node("save_output", self._save_output)
        
        # ã‚¨ãƒƒã‚¸ï¼ˆå‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼‰ã‚’å®šç¾©
        workflow.set_entry_point("load_input")
        workflow.add_edge("load_input", "analyze_structure")
        workflow.add_edge("analyze_structure", "split_text")
        workflow.add_edge("split_text", "enrich_metadata")
        workflow.add_edge("enrich_metadata", "format_yaml")
        workflow.add_edge("format_yaml", "save_output")
        workflow.add_edge("save_output", END)
        
        return workflow.compile()
    
    def _load_input(self, state: ProcessingState) -> ProcessingState:
        """
        å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            state: å‡¦ç†çŠ¶æ…‹
            
        Returns:
            ProcessingState: æ›´æ–°ã•ã‚ŒãŸå‡¦ç†çŠ¶æ…‹
        """
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—1: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ ===")
        
        try:
            input_path = Path(self.input_file)
            
            if not input_path.exists():
                raise FileNotFoundError(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.input_file}")
            
            with open(input_path, 'r', encoding='utf-8') as f:
                input_text = f.read()
            
            if not input_text.strip():
                raise ValueError("å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
            
            logger.info(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« {self.input_file} èª­ã¿è¾¼ã¿å®Œäº†: {len(input_text)}æ–‡å­—")
            
            state["input_text"] = input_text
            state["current_step"] = "load_input_complete"
            state["error_message"] = ""
            
        except Exception as e:
            logger.error(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            state["error_message"] = str(e)
            state["current_step"] = "load_input_error"
        
        return state
    
    def _analyze_structure(self, state: ProcessingState) -> ProcessingState:
        """
        ãƒ†ã‚­ã‚¹ãƒˆæ§‹é€ ã‚’åˆ†æã™ã‚‹
        
        Args:
            state: å‡¦ç†çŠ¶æ…‹
            
        Returns:
            ProcessingState: æ›´æ–°ã•ã‚ŒãŸå‡¦ç†çŠ¶æ…‹
        """
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—2: æ§‹é€ åˆ†æ ===")
        
        try:
            if state.get("error_message"):
                return state
            
            # SegmenterAgentã§æ§‹é€ åˆ†æ
            structure_analysis = self.segmenter.analyze_structure(state["input_text"])
            
            # æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
            book_title = structure_analysis.get("book_title", "ã‚¿ã‚¤ãƒˆãƒ«æœªè¨­å®š")
            
            logger.info(f"æ§‹é€ åˆ†æå®Œäº†: {len(structure_analysis['segments'])}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
            
            state["structure_analysis"] = structure_analysis
            state["book_title"] = book_title
            state["current_step"] = "analyze_structure_complete"
            
        except Exception as e:
            logger.error(f"æ§‹é€ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            state["error_message"] = str(e)
            state["current_step"] = "analyze_structure_error"
        
        return state
    
    def _split_text(self, state: ProcessingState) -> ProcessingState:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã™ã‚‹
        
        Args:
            state: å‡¦ç†çŠ¶æ…‹
            
        Returns:
            ProcessingState: æ›´æ–°ã•ã‚ŒãŸå‡¦ç†çŠ¶æ…‹
        """
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰² ===")
        
        try:
            if state.get("error_message"):
                return state
            
            # SplitterAgentã§ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
            segments = state["structure_analysis"]["segments"]
            text_chunks = self.splitter.split_text(state["input_text"], segments)
            
            # ãƒãƒ£ãƒ³ã‚¯ã‚’æœ€é©åŒ–
            optimized_chunks = self.splitter.optimize_chunks()
            
            logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å®Œäº†: {len(optimized_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
            
            state["text_chunks"] = optimized_chunks
            state["current_step"] = "split_text_complete"
            
        except Exception as e:
            logger.error(f"ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ã‚¨ãƒ©ãƒ¼: {e}")
            state["error_message"] = str(e)
            state["current_step"] = "split_text_error"
        
        return state
    
    def _enrich_metadata(self, state: ProcessingState) -> ProcessingState:
        """
        ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä»˜ä¸ã™ã‚‹
        
        Args:
            state: å‡¦ç†çŠ¶æ…‹
            
        Returns:
            ProcessingState: æ›´æ–°ã•ã‚ŒãŸå‡¦ç†çŠ¶æ…‹
        """
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸ ===")
        
        try:
            if state.get("error_message"):
                return state
            
            # LabelerAgentã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸
            enriched_chunks = self.labeler.enrich_chunks(
                state["text_chunks"], 
                state["book_title"]
            )
            
            # æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ”¹å–„
            enhanced_title = self.labeler.enhance_book_title(
                state["book_title"], 
                enriched_chunks
            )
            
            logger.info(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸å®Œäº†: {len(enriched_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
            
            state["enriched_chunks"] = enriched_chunks
            state["book_title"] = enhanced_title
            state["current_step"] = "enrich_metadata_complete"
            
        except Exception as e:
            logger.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸ã‚¨ãƒ©ãƒ¼: {e}")
            state["error_message"] = str(e)
            state["current_step"] = "enrich_metadata_error"
        
        return state
    
    def _format_yaml(self, state: ProcessingState) -> ProcessingState:
        """
        YAMLå½¢å¼ã«æ•´å½¢ã™ã‚‹
        
        Args:
            state: å‡¦ç†çŠ¶æ…‹
            
        Returns:
            ProcessingState: æ›´æ–°ã•ã‚ŒãŸå‡¦ç†çŠ¶æ…‹
        """
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—5: YAMLæ•´å½¢ ===")
        
        try:
            if state.get("error_message"):
                return state
            
            # YAMLFormatterAgentã§YAMLæ•´å½¢
            yaml_data = self.formatter.format_to_yaml(
                state["enriched_chunks"], 
                state["book_title"]
            )
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            enhanced_yaml = self.formatter.add_metadata(yaml_data)
            
            logger.info("YAMLæ•´å½¢å®Œäº†")
            
            state["yaml_data"] = enhanced_yaml
            state["current_step"] = "format_yaml_complete"
            
        except Exception as e:
            logger.error(f"YAMLæ•´å½¢ã‚¨ãƒ©ãƒ¼: {e}")
            state["error_message"] = str(e)
            state["current_step"] = "format_yaml_error"
        
        return state
    
    def _save_output(self, state: ProcessingState) -> ProcessingState:
        """
        å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹
        
        Args:
            state: å‡¦ç†çŠ¶æ…‹
            
        Returns:
            ProcessingState: æ›´æ–°ã•ã‚ŒãŸå‡¦ç†çŠ¶æ…‹
        """
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—6: å‡ºåŠ›ä¿å­˜ ===")
        
        try:
            if state.get("error_message"):
                return state
            
            # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            success = self.formatter.save_to_file(self.output_file, state["yaml_data"])
            
            if success:
                logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {self.output_file}")
                state["processing_complete"] = True
                state["current_step"] = "save_output_complete"
            else:
                raise Exception("ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"å‡ºåŠ›ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            state["error_message"] = str(e)
            state["current_step"] = "save_output_error"
        
        return state
    
    def process(self) -> bool:
        """
        æ›¸ç±æ§‹é€ åŒ–å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
        
        Returns:
            bool: å‡¦ç†æˆåŠŸãƒ•ãƒ©ã‚°
        """
        logger.info("æ›¸ç±æ§‹é€ åŒ–åˆ†å‰²ãƒ„ãƒ¼ãƒ«ã‚’é–‹å§‹ã—ã¾ã™")
        
        # åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
        initial_state = ProcessingState(
            input_text="",
            book_title="",
            structure_analysis={},
            text_chunks=[],
            enriched_chunks=[],
            yaml_data={},
            current_step="initialized",
            error_message="",
            processing_complete=False
        )
        
        try:
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
            final_state = self.workflow.invoke(initial_state)
            
            # çµæœã‚’ç¢ºèª
            if final_state.get("processing_complete"):
                logger.info("å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
                self._print_summary(final_state)
                return True
            else:
                logger.error(f"å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ: {final_state.get('error_message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
                return False
                
        except Exception as e:
            logger.error(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return False
    
    def _print_summary(self, final_state: ProcessingState):
        """
        å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›ã™ã‚‹
        
        Args:
            final_state: æœ€çµ‚å‡¦ç†çŠ¶æ…‹
        """
        print("\n" + "="*50)
        print("ğŸ“š æ›¸ç±æ§‹é€ åŒ–åˆ†å‰²ãƒ„ãƒ¼ãƒ« - å‡¦ç†å®Œäº†")
        print("="*50)
        
        print(f"ğŸ“– æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«: {final_state['book_title']}")
        print(f"ğŸ“„ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {self.input_file}")
        print(f"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {self.output_file}")
        
        if final_state.get("yaml_data"):
            chapters = final_state["yaml_data"].get("chapters", [])
            total_sections = sum(len(ch.get("sections", [])) for ch in chapters)
            
            print(f"ğŸ“š ç·ç« æ•°: {len(chapters)}")
            print(f"ğŸ“‘ ç·ç¯€æ•°: {total_sections}")
            
            if final_state["yaml_data"].get("metadata", {}).get("statistics"):
                stats = final_state["yaml_data"]["metadata"]["statistics"]
                print(f"ğŸ“Š ç·æ–‡å­—æ•°: {stats.get('total_content_length', 0):,}")
                # æ¨å®šèª­æ›¸æ™‚é–“ã®å‡ºåŠ›ã‚’å‰Šé™¤
        
        print("="*50)
        print("âœ… å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    parser = argparse.ArgumentParser(description='æ›¸ç±æ§‹é€ åŒ–åˆ†å‰²ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('input_file', help='å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('output_file', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    args = parser.parse_args()
    
    try:
        # ãƒ„ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
        structurer = TextBookStructurer(args.input_file, args.output_file)
        
        # å‡¦ç†ã‚’å®Ÿè¡Œ
        success = structurer.process()
        
        # çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’è¨­å®š
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        logger.info("å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()